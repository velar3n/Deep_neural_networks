{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505590aa",
   "metadata": {},
   "source": [
    "Autor: Natalia Kiełbasa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eff914",
   "metadata": {},
   "source": [
    "## Opis projektu - Sweep parametrów środowiska w części A1.4:\n",
    "\n",
    "### Co już mamy w pliku z rodziałem 3:\n",
    "Tutaj mamy bazując na A1.3 i A1.2 wyliczenie optymalnych polityk w zależności od zmieniających się parametrów środowiska. Jest to świetny przykład tego, że w trakcie jak zmienia nam się nasze otoczenie/środowisko, to nasza polityka (sposób działania) może przestać być optymalna. Tutaj (A1.4) mamy na bardzo prostym przykładzie - naszym modelu odkurzacza, który mam nadzieję już w miarę wszyscy rozumiemy, pokazane jak to się zmienia. \n",
    "W aktualnym przykładzie zmieniamy tylko beta dla 6 wartości oraz rescue_cost dla 4 wartości:\n",
    "\n",
    "- beta_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "- rescue_list = [-1.0, -3.0, -6.0, -10.0]\n",
    "\n",
    "Następnie iterujemy po nich i sprawdzamy dla każdej kombinacji optymalną politykę:\n",
    "\n",
    "- Ustawienia stałe: alpha= 0.8 r_search= 5.0 r_wait= 1.0 gamma= 0.9 \n",
    "- Obliczenia: beta rescue_cost pi(H) pi(L): 0.1 -1.0 SEARCH RECHARGE0.1 -3.0 SEARCH RECHARGE0.1 -6.0 SEARCH RECHARGE0.1 -10.0 SEARCH RECHARGE0.3 -1.0 SEARCH RECHARGE0.3 -3.0 SEARCH RECHARGE0.3 -6.0 SEARCH RECHARGE0.3 -10.0 SEARCH RECHARGE0.5 -1.0 SEARCH SEARCH 0.5 -3.0 SEARCH RECHARGE0.5 -6.0 SEARCH RECHARGE0.5 -10.0 SEARCH RECHARGE0.7 -1.0 SEARCH SEARCH 0.7 -3.0 SEARCH RECHARGE0.7 -6.0 SEARCH RECHARGE0.7 -10.0 SEARCH RECHARGE0.9 -1.0 SEARCH SEARCH 0.9 -3.0 SEARCH SEARCH 0.9 -6.0 SEARCH SEARCH 0.9 -10.0 SEARCH SEARCH Wskazówka: obserwuj, kiedy π*(L) zmienia się z SEARCH na RECHARGE.\n",
    "\n",
    "Widać na przykład, że nasz najprostszy działający i logiczny model - rozładowane to ładujemy, naładowane to odkurzamy nie zawsze jest optymalny. Da się to pewnie wytłumaczyć, np. skrajne sytuacje takie jak skrajnie zużyta bateria i szybko rozładowująca się (znamy z laptopów :).\n",
    "\n",
    "### Zadanie:\n",
    "W zadaniu chodzi o to, aby w tak prostym przykładzie pobawić się parametrami środowiska (alpha, beta, rescue_cost, gamma, r_wait, r_search) i zobaczyć jak nimi manipulując możemy uzyskiwać różne kombinacje optymanych polityk.\n",
    "1. Wykonać ręcznie w zadaniu A1.2 ewaluację kilku ręcznie wstawionych polityk i zobaczyć, które będą najlepsze. Pogrubione możemy zmieniać  sobie na inne możliwe akcje, aby zobaczyć co daje najlepszy wynik.\n",
    "- Polityka 1: w H -> SEARCH, w L -> RECHARGE\n",
    "- pi1 = np.zeros((nS, nA))\n",
    "- pi1[H, SEARCH] = 1.0\n",
    "- pi1[L, RECHARGE] = 1.0\n",
    "2. Następnie można przejść do A1.3, gdzie jest główny algorytm znajdujący optymalną politykę przy zadanych parametrach.\n",
    "3. (główna część zadania) W części A1.4 wykonujemy \"sweepy\" po różnych zestawach parametrów środowiska, oczywiście nie po wszystkich, tylklo proszę wybrać kilka i spróbować ocenić z czego to wynika/zinterepretować.\n",
    "4. Ważne! Trzeba jasno napisać:\n",
    "- co jest częścią środowiska\n",
    "- co jest częścią agenta\n",
    "- jaką mamy politykę\n",
    "- jak wyliczamy funkcję wartości V_{pi}\n",
    "- jak ewaluujemy politykę"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
