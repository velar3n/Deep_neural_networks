{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3669a0-284c-48f7-9c73-19812e2a8fac",
   "metadata": {
    "id": "9c3669a0-284c-48f7-9c73-19812e2a8fac"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23273a2",
   "metadata": {},
   "source": [
    "# !!!!   Zwróćcie uwagę accuracy naszego modelu wzrosło! :)  !!!!!\n",
    "\n",
    "tensor(0.9211)\n",
    "\n",
    "vs.\n",
    "\n",
    "tensor(0.9474)\n",
    "\n",
    "To dzięki              \n",
    "\n",
    "self.loss = nn.MSELoss(reduction='sum') \n",
    "\n",
    "vs.   \n",
    "\n",
    "self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Zwróćcie też uwagę na to:\n",
    "\n",
    "predictions = model(input_test_tensors)\n",
    "predicted_labels = torch.argmax(predictions, dim=1)\n",
    "torch.sum(torch.eq(torch.tensor(label_test), predicted_labels)) / len(predicted_labels)\n",
    "\n",
    "W przeciwieństwie do poprzedniej sieci, gdzie wykonaliśmy na ostatniej warstwie regresję i przewidywaliśmy\n",
    "wartości, tutaj mamy do czynienia z klasyfikacją i mamy skuteczność (accuracy) klasyfikacji jako jedną z możliwych\n",
    "miar: 92% vs 95%.\n",
    "W celu wykonania takiej klasyfikacji na ostatniej warstwie musimy wykorzystać funkcję argmax, czyli\n",
    "popatrzcie dostajemy np. w klasyfikacji 3 wartości np. [0.4,0.8,0.1], po wybraniu argmax zwraca  nam 1, czyli wybieramy gatunek o indeksie 1 zgodnie z naszą faktoryzacją i oznaczeniami one_hot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d678b988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in /home/piotr/anaconda3/lib/python3.8/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (0.11.9)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (6.0.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (22.0)\n",
      "Requirement already satisfied: torch<4.0,>=2.0.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (2.4.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (1.5.2)\n",
      "Requirement already satisfied: fsspec[http]<2026.0,>=2022.5.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (4.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning) (2.4.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/piotr/anaconda3/lib/python3.8/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/piotr/anaconda3/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: setuptools in /home/piotr/anaconda3/lib/python3.8/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (52.0.0.post20210125)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.0.106)\n",
      "Requirement already satisfied: filelock in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.16.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (11.4.5.107)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (2.20.5)\n",
      "Requirement already satisfied: jinja2 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (1.8)\n",
      "Requirement already satisfied: networkx in /home/piotr/anaconda3/lib/python3.8/site-packages (from torch<4.0,>=2.0.0->lightning) (2.6.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/piotr/anaconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.0.0->lightning) (12.3.101)\n",
      "Requirement already satisfied: idna>=2.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/piotr/anaconda3/lib/python3.8/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/piotr/anaconda3/lib/python3.8/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.2.1)\n",
      "Iris-setosa: 50\n",
      "Iris-versicolor: 50\n",
      "Iris-virginica: 50\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning\n",
    "import torch # torch will allow us to create tensors.\n",
    "import torch.nn as nn # torch.nn allows us to create a neural network.\n",
    "import torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\n",
    "from torch.optim import Adam # optim contains many optimizers. This time we're using Adam\n",
    "\n",
    "import lightning as L # lightning has tons of cool tools that make neural networks easier\n",
    "from torch.utils.data import TensorDataset, DataLoader # these are needed for the training data\n",
    "\n",
    "import pandas as pd # We'll use pandas to read in the data and normalize it\n",
    "from sklearn.model_selection import train_test_split\n",
    "url = \"./iris.txt\"\n",
    "df = pd.read_table(url, sep=\",\", header=None)\n",
    "df.head()\n",
    "df.columns = [\"sepal_length\",\n",
    "              \"sepal_width\",\n",
    "              \"petal_length\",\n",
    "              \"petal_width\",\n",
    "              \"class\"]\n",
    "df.head()\n",
    "df.shape\n",
    "df['class'].nunique()\n",
    "df['class'].unique()\n",
    "for class_name in df['class'].unique(): # for each unique class name...\n",
    "    ## ...print out the number of rows associated with it\n",
    "    print(class_name, \": \", sum(df['class'] == class_name), sep=\"\")\n",
    "df[['petal_width', 'sepal_width']].head()\n",
    "input_values = df[['petal_width', 'sepal_width']]\n",
    "input_values.head()\n",
    "label_values = df['class']\n",
    "label_values.head()\n",
    "classes_as_numbers = label_values.factorize()[0]\n",
    "classes_as_numbers \n",
    "input_train, input_test, label_train, label_test = train_test_split(input_values,\n",
    "                                                                    classes_as_numbers,\n",
    "                                                                    test_size=0.25,\n",
    "                                                                    stratify=classes_as_numbers,\n",
    "                                                                    random_state=42)\n",
    "one_hot_label_train = F.one_hot(torch.tensor(label_train)).type(torch.float32)\n",
    "max_vals_in_input_train = input_train.max()\n",
    "max_vals_in_input_train\n",
    "min_vals_in_input_train = input_train.min()\n",
    "\n",
    "min_vals_in_input_train\n",
    "input_train = (input_train - min_vals_in_input_train) / (max_vals_in_input_train - min_vals_in_input_train)\n",
    "input_train.head()\n",
    "input_test = (input_test - min_vals_in_input_train) / (max_vals_in_input_train - min_vals_in_input_train)\n",
    "input_test.head()\n",
    "input_train_tensors = torch.tensor(input_train.values).type(torch.float32)\n",
    "input_test_tensors = torch.tensor(input_test.values).type(torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(input_train_tensors, one_hot_label_train)\n",
    "train_dataloader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e66ff-db47-4057-9f50-7c9576ec58ee",
   "metadata": {
    "id": "e18e66ff-db47-4057-9f50-7c9576ec58ee"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645699fb-e215-46f2-b730-2e9276d0a407",
   "metadata": {
    "id": "645699fb-e215-46f2-b730-2e9276d0a407",
    "tags": []
   },
   "source": [
    "<a id=\"train\"></a>\n",
    "# Training our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fa43642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleInsOuts(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42)\n",
    "        self.input_to_hidden = nn.Linear(in_features=2, out_features=2, bias=True)\n",
    "        self.hidden_to_output = nn.Linear(in_features=2, out_features=3, bias=True)\n",
    "\n",
    "        self.loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        ## First, we run the input values to the activation functions\n",
    "        ## in the hidden layer\n",
    "        hidden = self.input_to_hidden(input)\n",
    "        output_values = self.hidden_to_output(torch.relu(hidden))\n",
    "\n",
    "        return(output_values)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        loss = self.loss(outputs, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a3cac-ccb9-49d2-96fc-b797d7e0823c",
   "metadata": {
    "id": "6c2a3cac-ccb9-49d2-96fc-b797d7e0823c"
   },
   "source": [
    "Training our new neural network means we create a model from the new class, `MultipleInsOuts`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e34ca1ef-4635-4630-a4d0-0ddf5bb2022d",
   "metadata": {
    "id": "e34ca1ef-4635-4630-a4d0-0ddf5bb2022d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "model = MultipleInsOuts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bee5f1bc-fcef-4cac-b33e-1225ec246f2d",
   "metadata": {
    "id": "bee5f1bc-fcef-4cac-b33e-1225ec246f2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type    | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | input_to_hidden  | Linear  | 6      | train\n",
      "1 | hidden_to_output | Linear  | 9      | train\n",
      "2 | loss             | MSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "15        Trainable params\n",
      "0         Non-trainable params\n",
      "15        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/home/piotr/anaconda3/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d59ce1b5574998a01dded2999d020b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fcdcfd9-36f1-44d2-ae8c-3b3f78e99693",
   "metadata": {
    "id": "0fcdcfd9-36f1-44d2-ae8c-3b3f78e99693"
   },
   "outputs": [],
   "source": [
    "predictions = model(input_test_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d258a469-33ae-4941-a5b8-86f9b1499ac4",
   "metadata": {
    "id": "d258a469-33ae-4941-a5b8-86f9b1499ac4"
   },
   "source": [
    "Now, because our neural network has three outputs, one for **Setosa**, one for **Versicolor**, and one for **Virginica**, we should get 3 values for each row in `input_test_tensors`. We can verify that by looking at the first few rows of `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ec2ed77-e863-40fb-9142-2da3ec9f3f78",
   "metadata": {
    "id": "6ec2ed77-e863-40fb-9142-2da3ec9f3f78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7585, 0.0282, 0.0331],\n",
       "        [0.1994, 0.3877, 0.4948],\n",
       "        [0.2486, 0.3490, 0.3868],\n",
       "        [0.1941, 0.3776, 0.3712]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:4,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52512e0f-9a49-4080-aeea-ceac0745ca5a",
   "metadata": {
    "id": "52512e0f-9a49-4080-aeea-ceac0745ca5a"
   },
   "source": [
    "We can determine which species was predicted in `predictions` by selecting the index in each row that corresponding to the largest value, and we do that with `torch.argmax()`. `torch.argmax()` returns a tensor that contains the indices with the largest values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a336e70-1e01-48a2-9761-cb51c845dbbb",
   "metadata": {
    "id": "8a336e70-1e01-48a2-9761-cb51c845dbbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 2, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = torch.argmax(predictions, dim=1) ## dim=0 applies argmax to rows, dim=1 applies argmax to columns\n",
    "predicted_labels[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb622159-b415-4e2e-83af-328cabad438e",
   "metadata": {
    "id": "bb622159-b415-4e2e-83af-328cabad438e"
   },
   "source": [
    "In the first row index 0 had the largest value. Thus, the first prediction corresponds to **Setosa**. The second, third, and fourth rows predicted 2, which corresponds to **Virginica**.\n",
    "\n",
    "Now, let's compare what the neural network predicted in `predicted_labels` to the known values in `label_test` and calculate the percentage of correct predictions. We do this by adding up the number of times an element in `predicted_labels` equals the corresponding element in `label_test` and dividing by the number of elements in `predicted_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0872e381-57ef-43e3-a6b4-9aa9d96c93e4",
   "metadata": {
    "id": "0872e381-57ef-43e3-a6b4-9aa9d96c93e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7368)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now compare predicted_labels with test_labels to calculate accuracy\n",
    "## NOTE: torch.eq() computes element-wise equality between two tensors.\n",
    "torch.sum(torch.eq(torch.tensor(label_test), predicted_labels)) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd75320-d89e-4928-84ba-9b3baaa966c5",
   "metadata": {
    "id": "2dd75320-d89e-4928-84ba-9b3baaa966c5"
   },
   "source": [
    "And we see that our neural network only correctly predicts 74% of the testing data. This isn't very good. So, will training our model for more epochs improve the model's predictions?\n",
    "\n",
    "One way to answer that question is to just train for longer and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b8180-976d-4c1e-b2e7-cb45cba434c9",
   "metadata": {
    "id": "754b8180-976d-4c1e-b2e7-cb45cba434c9"
   },
   "source": [
    "To add additional epochs to the training, we first identify where the checkpoint file is with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29bc4c1b-911d-417f-8ab2-9f52712502e8",
   "metadata": {
    "id": "29bc4c1b-911d-417f-8ab2-9f52712502e8"
   },
   "outputs": [],
   "source": [
    "path_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a849d2f-bad1-4214-a72b-f1b04174639c",
   "metadata": {
    "id": "5a849d2f-bad1-4214-a72b-f1b04174639c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_11/checkpoints/epoch=9-step=1120.ckpt\n",
      "/home/piotr/anaconda3/lib/python3.8/site-packages/lightning/fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/home/piotr/anaconda3/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:360: The dirpath has changed from '/home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_11/checkpoints' to '/home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_12/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type    | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | input_to_hidden  | Linear  | 6      | train\n",
      "1 | hidden_to_output | Linear  | 9      | train\n",
      "2 | loss             | MSELoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "15        Trainable params\n",
      "0         Non-trainable params\n",
      "15        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_11/checkpoints/epoch=9-step=1120.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03a9795fcd940a0a2f95517a4851f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "## First, create a new Lightning Trainer\n",
    "trainer = L.Trainer(max_epochs=100) # Before, max_epochs=10, so, by setting it to 100, we're adding 90 more.\n",
    "\n",
    "## Then call trainer.fit() using the path to the most recent checkpoint files\n",
    "## so that we can pick up where we left off.\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, ckpt_path=path_to_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe10d75",
   "metadata": {},
   "source": [
    "# ACCURACY 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca3ecd4-f56d-4a1e-89cc-1f7cf5992a1e",
   "metadata": {
    "id": "7ca3ecd4-f56d-4a1e-89cc-1f7cf5992a1e"
   },
   "source": [
    "Now, let's run the testing data through the network and calculate the accuracy. We'll do this just like we did before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a82e4c",
   "metadata": {},
   "source": [
    "## ARGMAX - pamiętajcie - klasyfikacja!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fb462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "930f26fe-eca7-46a3-9652-0e1d1b1bcfb6",
   "metadata": {
    "id": "930f26fe-eca7-46a3-9652-0e1d1b1bcfb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9211)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(input_test_tensors)\n",
    "predicted_labels = torch.argmax(predictions, dim=1)\n",
    "torch.sum(torch.eq(torch.tensor(label_test), predicted_labels)) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31918cf1-5cfc-475b-b61a-f08525111741",
   "metadata": {
    "id": "31918cf1-5cfc-475b-b61a-f08525111741"
   },
   "source": [
    "After 100 training epochs, we correctly classified 92% of the testing data. This means adding more training was helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b568a1ad-f6d4-436f-8c58-b39371680175",
   "metadata": {
    "id": "b568a1ad-f6d4-436f-8c58-b39371680175"
   },
   "source": [
    "<a id=\"predict\"></a>\n",
    "# Make a Prediction with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8759e954-3d0b-4ac3-84ac-5c294585643a",
   "metadata": {
    "id": "8759e954-3d0b-4ac3-84ac-5c294585643a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal_width    0.041667\n",
       "sepal_width    0.416667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_values = ([0.2, 3.0] - min_vals_in_input_train) / (max_vals_in_input_train - min_vals_in_input_train)\n",
    "normalized_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e1e78-d0dd-46c8-9cd5-f59815385dea",
   "metadata": {
    "id": "211e1e78-d0dd-46c8-9cd5-f59815385dea"
   },
   "source": [
    "Then we convert `normalized_values` into a tensor and pass it to the model to see what it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2759e9fd-0f5e-40f2-a004-572fa2daf97b",
   "metadata": {
    "id": "2759e9fd-0f5e-40f2-a004-572fa2daf97b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7956,  0.1990, -0.0419], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(normalized_values).type(torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053241f-37bb-44b3-b2da-38e841679422",
   "metadata": {
    "id": "2053241f-37bb-44b3-b2da-38e841679422"
   },
   "source": [
    "And first output has the largest value, meaning that the neural network predicts that the measurements come from **Setosa**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e221b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f0f33e",
   "metadata": {},
   "source": [
    "# We now increase the accuracy through Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c8cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15ed8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleInsOuts(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        L.seed_everything(seed=42)\n",
    "        self.input_to_hidden = nn.Linear(in_features=2, out_features=2, bias=True)\n",
    "        self.hidden_to_output = nn.Linear(in_features=2, out_features=3, bias=True)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = self.input_to_hidden(input)\n",
    "        output_values = self.hidden_to_output(torch.relu(hidden))\n",
    "\n",
    "        return(output_values)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        loss = self.loss(outputs, labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1e528b8",
   "metadata": {
    "id": "e34ca1ef-4635-4630-a4d0-0ddf5bb2022d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "model = MultipleInsOuts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d051148",
   "metadata": {
    "id": "bee5f1bc-fcef-4cac-b33e-1225ec246f2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | input_to_hidden  | Linear           | 6      | train\n",
      "1 | hidden_to_output | Linear           | 9      | train\n",
      "2 | loss             | CrossEntropyLoss | 0      | train\n",
      "--------------------------------------------------------------\n",
      "15        Trainable params\n",
      "0         Non-trainable params\n",
      "15        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752071706e3e49329a9360583408c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d62f1d04",
   "metadata": {
    "id": "0fcdcfd9-36f1-44d2-ae8c-3b3f78e99693"
   },
   "outputs": [],
   "source": [
    "predictions = model(input_test_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac9846",
   "metadata": {
    "id": "d258a469-33ae-4941-a5b8-86f9b1499ac4"
   },
   "source": [
    "Now, because our neural network has three outputs, one for **Setosa**, one for **Versicolor**, and one for **Virginica**, we should get 3 values for each row in `input_test_tensors`. We can verify that by looking at the first few rows of `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e53012ce",
   "metadata": {
    "id": "6ec2ed77-e863-40fb-9142-2da3ec9f3f78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9644, -0.1377,  0.0748],\n",
       "        [ 0.0507,  0.5664,  0.8702],\n",
       "        [ 0.1509,  0.4944,  0.6980],\n",
       "        [ 0.1030,  0.5353,  0.6764]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:4,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52fdaac",
   "metadata": {
    "id": "52512e0f-9a49-4080-aeea-ceac0745ca5a"
   },
   "source": [
    "We can determine which species was predicted in `predictions` by selecting the index in each row that corresponding to the largest value, and we do that with `torch.argmax()`. `torch.argmax()` returns a tensor that contains the indices with the largest values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b1aef9e",
   "metadata": {
    "id": "8a336e70-1e01-48a2-9761-cb51c845dbbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the output with highest value...\n",
    "predicted_labels = torch.argmax(predictions, dim=1) ## dim=0 applies argmax to rows, dim=1 applies argmax to columns\n",
    "predicted_labels[0:4] # print out the first 4 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd7f6e",
   "metadata": {
    "id": "bb622159-b415-4e2e-83af-328cabad438e"
   },
   "source": [
    "In the first row index 0 had the largest value. Thus, the first prediction corresponds to **Setosa**. The second, third, and fourth rows predicted 2, which corresponds to **Virginica**.\n",
    "\n",
    "Now, let's compare what the neural network predicted in `predicted_labels` to the known values in `label_test` and calculate the percentage of correct predictions. We do this by adding up the number of times an element in `predicted_labels` equals the corresponding element in `label_test` and dividing by the number of elements in `predicted_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed5f2a52",
   "metadata": {
    "id": "0872e381-57ef-43e3-a6b4-9aa9d96c93e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6579)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.eq(torch.tensor(label_test), predicted_labels)) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d57de",
   "metadata": {
    "id": "2dd75320-d89e-4928-84ba-9b3baaa966c5"
   },
   "source": [
    "And we see that our neural network only correctly predicts 66% of the testing data. This isn't very good. So, will training our model for more epochs improve the model's predictions?\n",
    "\n",
    "One way to answer that question is to just train for longer and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6193b07",
   "metadata": {
    "id": "754b8180-976d-4c1e-b2e7-cb45cba434c9"
   },
   "source": [
    "To add additional epochs to the training, we first identify where the checkpoint file is with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "828085ae",
   "metadata": {
    "id": "29bc4c1b-911d-417f-8ab2-9f52712502e8"
   },
   "outputs": [],
   "source": [
    "path_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbc120",
   "metadata": {
    "id": "6d4fd497-997c-4369-9b3e-d25cd0911d5d"
   },
   "source": [
    "Then we create a new Lightning Trainer, just like before, but we set the number of epochs to 100. Given that we already trained for 10 epochs, this means we'll do 90 more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0523c42d",
   "metadata": {
    "id": "5a849d2f-bad1-4214-a72b-f1b04174639c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_13/checkpoints/epoch=9-step=1120.ckpt\n",
      "/home/piotr/anaconda3/lib/python3.8/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:360: The dirpath has changed from '/home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_13/checkpoints' to '/home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_14/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | input_to_hidden  | Linear           | 6      | train\n",
      "1 | hidden_to_output | Linear           | 9      | train\n",
      "2 | loss             | CrossEntropyLoss | 0      | train\n",
      "--------------------------------------------------------------\n",
      "15        Trainable params\n",
      "0         Non-trainable params\n",
      "15        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /home/piotr/Documents/zajecia/DNN/CS-DNN/tutorials/3/lightning_logs/version_13/checkpoints/epoch=9-step=1120.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de0ca395ab24a25853120c5339f24f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=100)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, ckpt_path=path_to_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed997290",
   "metadata": {},
   "source": [
    "# ACCURACY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c431a",
   "metadata": {},
   "source": [
    "## ARGMAX - pamiętajcie - klasyfikacja!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887129f4",
   "metadata": {
    "id": "7ca3ecd4-f56d-4a1e-89cc-1f7cf5992a1e"
   },
   "source": [
    "Now, let's run the testing data through the network and calculate the accuracy. We'll do this just like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b2883ca",
   "metadata": {
    "id": "930f26fe-eca7-46a3-9652-0e1d1b1bcfb6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9474)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(input_test_tensors)\n",
    "predicted_labels = torch.argmax(predictions, dim=1)\n",
    "torch.sum(torch.eq(torch.tensor(label_test), predicted_labels)) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448768b",
   "metadata": {},
   "source": [
    "# !!!!   Zwróćcie uwagę accuracy naszego modelu wzrosło! :)  !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39471e",
   "metadata": {},
   "source": [
    "tensor(0.9211)\n",
    "\n",
    "vs.\n",
    "\n",
    "tensor(0.9474)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12008e62",
   "metadata": {},
   "source": [
    "To dzięki         self.loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8884c5e3",
   "metadata": {
    "id": "31918cf1-5cfc-475b-b61a-f08525111741"
   },
   "source": [
    "### After 100 training epochs, we correctly classified 95% of the testing data. This means adding more training was helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f64162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a2b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a542159",
   "metadata": {
    "id": "b568a1ad-f6d4-436f-8c58-b39371680175"
   },
   "source": [
    "<a id=\"predict\"></a>\n",
    "# Make a Prediction with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a22bbd05",
   "metadata": {
    "id": "8759e954-3d0b-4ac3-84ac-5c294585643a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal_width    0.041667\n",
       "sepal_width    0.416667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_values = ([0.2, 3.0] - min_vals_in_input_train) / (max_vals_in_input_train - min_vals_in_input_train)\n",
    "normalized_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb1b64",
   "metadata": {
    "id": "211e1e78-d0dd-46c8-9cd5-f59815385dea"
   },
   "source": [
    "Then we convert `normalized_values` into a tensor and pass it to the model to see what it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "435ada7c",
   "metadata": {
    "id": "2759e9fd-0f5e-40f2-a004-572fa2daf97b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.0464,  1.5474, -6.4604], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(normalized_values).type(torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d37245",
   "metadata": {
    "id": "2053241f-37bb-44b3-b2da-38e841679422"
   },
   "source": [
    "And first output has the largest value, meaning that the neural network predicts that the measurements come from **Setosa**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
